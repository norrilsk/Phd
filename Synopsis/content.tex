\pdfbookmark{Общая характеристика работы}{characteristic}             % Закладка pdf
\section*{Общая характеристика работы}

\newcommand{\actuality}{\pdfbookmark[1]{Актуальность}{actuality}\underline{\textbf{\actualityTXT}}}
\newcommand{\progress}{\pdfbookmark[1]{Разработанность темы}{progress}\underline{\textbf{\progressTXT}}}
\newcommand{\aim}{\pdfbookmark[1]{Цели}{aim}\underline{{\textbf\aimTXT}}}
\newcommand{\tasks}{\pdfbookmark[1]{Задачи}{tasks}\underline{\textbf{\tasksTXT}}}
\newcommand{\aimtasks}{\pdfbookmark[1]{Цели и задачи}{aimtasks}\aimtasksTXT}
\newcommand{\novelty}{\pdfbookmark[1]{Научная новизна}{novelty}\underline{\textbf{\noveltyTXT}}}
\newcommand{\influence}{\pdfbookmark[1]{Практическая значимость}{influence}\underline{\textbf{\influenceTXT}}}
\newcommand{\methods}{\pdfbookmark[1]{Методология и методы исследования}{methods}\underline{\textbf{\methodsTXT}}}
\newcommand{\defpositions}{\pdfbookmark[1]{Положения, выносимые на защиту}{defpositions}\underline{\textbf{\defpositionsTXT}}}
\newcommand{\reliability}{\pdfbookmark[1]{Достоверность}{reliability}\underline{\textbf{\reliabilityTXT}}}
\newcommand{\probation}{\pdfbookmark[1]{Апробация}{probation}\underline{\textbf{\probationTXT}}}
\newcommand{\contribution}{\pdfbookmark[1]{Личный вклад}{contribution}\underline{\textbf{\contributionTXT}}}
\newcommand{\publications}{\pdfbookmark[1]{Публикации}{publications}\underline{\textbf{\publicationsTXT}}}

\input{common/characteristic} % Характеристика работы по структуре во введении и в автореферате не отличается (ГОСТ Р 7.0.11, пункты 5.3.1 и 9.2.1), потому её загружаем из одного и того же внешнего файла, предварительно задав форму выделения некоторым параметрам

%Диссертационная работа была выполнена при поддержке грантов \dots

%\underline{\textbf{Объем и структура работы.}} Диссертация состоит из~введения,
%четырех глав, заключения и~приложения. Полный объем диссертации
%\textbf{ХХХ}~страниц текста с~\textbf{ХХ}~рисунками и~5~таблицами. Список
%литературы содержит \textbf{ХХX}~наименование.

\pdfbookmark{Содержание работы}{description}                          % Закладка pdf
\section*{Содержание работы}

Во \underline{\textbf{введении}} обосновывается актуальность исследований, проводимых в рамках данной диссертационной работы, приводится обзор научной литературы по изучаемой проблеме, формулируется цель, ставятся задачи, излагается научная новизна и практическая значимость представленного исследования. В последующих главах сначала производится обзор существующих решений по данной тематике, затем описывается методология получения новых оптимизаций а также принципы и сложности замера итоговой производительности. В последней главе описаны алгоритмы, которые позволили улучшить производительность приложений и преодолеть недостатки целевой архитектуры.


\underline{\textbf{Первая глава}} посвящена обзору существующих алгоритмов оптимизации
для ARM64 и других подобных RISC-архитектур. Классические и известные
компиляторные оптимизации (такие как удаление мертвого кода, поиск общих
подвыражений, ленивое перемещение кода и подобные) не описываются в данной работе и считаются общеизвестными, однако могут быть описаны их модификации, которые
позволяют получить улучшение производительности для архитектуры ARM64.
GCC является одним из наиболее известных статических трансляторов
кода. Количество оптимизирующих проходов этого компилятора исчисляется
сотнями, и, тем не менее, его улучшение происходит до сих пор, и каждый
год обнаруживаются новые возможности для оптимизации даже в классических
проходах. 




\underline{\textbf{В разделе 1.1}} приводится описание методологии распределения регистров
и ее современные улучшения. Распределение регистров наравне с выбором и расстановкой инструкций
является одной из самых сложных оптимизаций в компиляторе. В  основе распределения регистров лежит проблема ограниченности размера
регистрового файла аппаратуры. Компилятор внутри себя чаще всего
использует так называемые виртуальные регистры, количество которых неограниченно,
и компилятор не заботится об их переиспользовании. Существуют два базовых алгоритма решения данной задачи: раскраска графа и линейное сканирование. Алгоритм раскараски графа чаще всего дает лучшее решение, однако, когда речь идет о системах, к которым выдвигаются требования
высокой производительности, например, бинарная трансляция, то часто используется
метод линейного санирования. Рассматривается  оптимизация, в которой вводится понятие "активная в
будущем"\phantom{} переменная - переменная, которая будет использоваться инструкциями
при дальнейшем сканировании. Это позволило добиться того, что для 90 \%
инструкций и 80 \% методов модель анализа интервалов жизни стала ненужной. Другая рассмотренная работа показывает, что современный рассматриваемый в работе компилятор все еще может генерировать лишние инструкции загрузки из памяти в
следствие неточности округлений, связанных с использованием целочисленных
вероятностей в компиляторе GCC.

\underline{\textbf{В разделе 1.2}}  рассматривается оптимизация векторизации, развитие которой
тесно связано с развитием современных векторных архитектур. Векторизация до сих пор является слабым местом для компиляторов. До сих пор авторы многих печатных работ вынуждены векторизовать программный код вручную.  В разделе приводятся примеры статей, в которых авторы занимаются ручной векторизацией кода.  
расширений. В рассматриваемых работах по автовекторизации указывается, что основной
преградой для векторизации является сложная структура графа потока управления,
которая препятствует стандартным алгоритмам векторизации кода. Так,
например, в листинге \ref{syn:review_vec1} исполнение условия является управлением, препятствующим
векторизации.

\begin{ListingEnv}[!h]
	\captiondelim{ } % разделитель идентификатора с номером от наименования
	\caption{Пример цикла, содержащего управления.}\label{syn:review_vec1}
	
	\begin{Verb}
	  int arr[n], a[n],  b[n], out[n];
	  ... code ...
	  for (int i = 0; i< n; i++) {
	  	if (cond1[i] & cond2[n-1]){
	  		out[i] = a[i] + b[i];  
	  	}
	  }
	  ... code ...
	\end{Verb}
\end{ListingEnv}

Другое направление, которое стоит отметить - это "библиотечная векторизация функций". В таких работах пользователи в ручном режиме превращают отдельные участки кода в библиотечные функции. Так, например, векторизация стандартных математических
функций  позволяет добиться значительного ускорения незримо для пользователя.
К сожалению, такой подход не позволит векторизовать математическую
функцию,написанную собственноручно.

\underline{\textbf{В разделе 1.3}} обсуждается проблема задержек, связанных с взаимодействием
приложения и подсистемы памяти. Известно, что время доступа в оперативную
память значительно превышает время исполнения одной инструкции.
Для решения этой проблемы были созданы различные техники кэширования и
предзагрузки данных в кэш. Однако на кристалле невозможно разместить
слишком сложную логику ввиду ограничений на размеры и потребление
мощности, к тому же у компилятора или пользователя имеется больше информации
о структуре программы, чем у аппаратуры во время исполнения. Классическим примером такой оптимизации является предзагрузка данных
для циклов. такая оптимизация позволяет добиться ускорения до 90 \%  на отдельных тестах.

Одним из современных направлений является разработка
алгоритмов для предзагрузки данных при косвенных доступах в память. В работе
сотрудников Кэмбриджского университета упоминается разработка
алгоритма предзагрузки данных в компиляторе LLVM для косвенного доступа (смотри рисунок \ref{syn:prefetch3}).
Их подход нацелен на системы с высокопроизводительными вычислениями и
позволил получить ускорение от 30 \% до 270 \%, к сожалению не были продемонстрированы
результаты на тестах SpecCPU. 

\begin{figure}[htbp]
	\centering
	\includesvg[width = 170pt, inkscapelatex=false ]{SVG/indirect_prefetch_review.drawio.svg}
	\caption{Пример косвенной адресации данных.}
	\label{syn:prefetch3}
\end{figure}

\underline{\textbf{В разделе 1.4}} описывается задача подбора оптимальных параметров компиляции
для целевого приложения на целевой платформе. Во время компиляции приходится
решать очень много NP-полных задач. До сих пор огромное количество алгоритмов
компилятора предполагают эвристические параметры и методы.
Современное популярное направление нацелено  на автоматизацию получения этих параметров или их полную замену. В обзорной статье была  выделена общая схема автотюнера (Рисунок \ref{syn:ml_for_comp1}). Вверху
рисунка: набор данных проходит через различные этапы обучения, на котором
создается модель на основе обучающего набора данных. Внизу: набор данных
проходит через различные этапы тестирования, где обучающая модель используется
для прогнозирования результата. Описано множество работ, которые получают прирост производительности более 20 \% благодаря этой технологии, однако до сих пор существует множество нерешенных проблем. Одной из таких проблем является создание тренировочной базы тестов для задач машинного обучения. 
Для обучения модели количество тестов должно измеряться тысячами, и тесты SpecCPU не являются подходящими для такой задачи. Другая проблема связана с огромным пространством поиска оптимальных опций.  Для сокращения такого пространства вводится алгоритм поиска критических
флагов. Интересно, что помимо программы, алгоритм принимает на вход
документацию компилятора GCC. Утверждается, что такой подход позволяет
получить лучшие цифры по сравнению с другими системами автоматической
настройки компилятора.



 \begin{figure}[htbp]
	\centering
	\includesvg[width = 300pt, inkscapelatex=false ]{SVG/ml_for_compilers1.drawio.svg}
	\caption{Общая схема автоматической настройки компилятора.}
	\label{syn:ml_for_comp1}
\end{figure}



В конце первой главы, \underline{\textbf{в разделе 1.5}}, обсуждаются оптимизации с использованием
профиля, и, хотя в данном исследовании динамическая профильная
информация была недоступна, методы динамической оптимизации могут быть
использованы в статических трансляторах с определенными ограничениями.  

 Использование профиля позволяет разрешить такие задачи, как девиртуализация, расстановка базовых блоков, выравнивание адресов и т.д. Необходимо сказать, что  подобные исследование упирались в нежелание пользователей перекомпилировать свои приложения, а также в проблему зависимости профиля исполнения от входных данных. Поэтому долгое  время популярными были только системы бинарной трансляции, которые могут динамически подстраиваться под меняющийся поток данных. Более того, давление бизнеса привело к тому, что использование профиля для получения результатов SpecCPU стало запрещено, для этого была выделенная отдельная категория "SpecCPU speed"\phantom{}, которая позволяет показывать наилучший результаты независимо для каждого приложения.
\begin{figure}[htbp]
	\centering
	\includesvg[width = 300pt, inkscapelatex=false ]{SVG/revirewFDO.drawio.svg}
	\caption{Общая схема статической оптимизации с использованием профиля.}
	\label{partReview:fdo1}
\end{figure}

В 2016 году Google разработала систему автоматического сбора профиля и оффлайн рекомпиляции приложений пользователей. Во время запуска пользовательских приложений фоном собиралась статистика с помощью сэмплирующего профилировщика, затем, когда сервер простаивал, запускался механизм обработки профильных данных и процесс рекомпиляции. Такой подход по заверению авторов увеличивал производительность приложений на 10 \%.  


Сергей Лисицын  в своей диссертации предлагает разрешить проблему зависимости профиля от входных данных с помощью версионирования отдельных участков программы, выбор между которыми делается динамически во время исполнения. Из недостатков подобного решения можно отметить увеличение размеров исполняемого файла.

С популяризацией машинного обучения появилась возможность генерации качественного синтетического профиля. Авторы статьи натренировали бустинг над деревьями для генерации профильной информации, что в свою очередь позволило компилятору использовать этот профиль и применять соответствующие оптимизации. С помощью данного подхода авторам удалось добиться ускорения в 1.6 процента в среднем с максимальным результатом в 16 \%  на интерпретаторе языка Python. 



\underline{\textbf{Во второй главе}} рассматривается методология поиска неоптимальностей в коде приложений и замера производительности. Для решения поставленной задачи - улучшения
компилятора - необходимо определить неоптимальные места в коде, сгенерированным компилятором, которые при исполнении показывают недостаточную эффективность или вызывают задержку конвейера исполнения.

\underline{\textbf{В разделе 2.1}}
дается описание целевой платформы, под которую разрабатывались
оптимизации. Для проведения исследований был выбран широко распространенный сервер компании Huawei - Kunpeng920. Он базируется на архитектуре ARM V8.2-A.  Основным конкурентом данного процессора на архитектуре ARM является Ampere Altra Server.  Исследуемая модель процессора создана по 7-нанометровой технологии и оснащена 64 ядрами с тактовой частотой 2.6 ГГц. Модель включает в себя  ряд аппаратных ускорителей, в том числе криптографии (MD5, HMAC, CMAC, AES, DES/3DES,  SHA1, SHA2) и  алгоритмов сжатия (GZIP, LZS, LZ4). 
Каждый чип состоит из двух вычислительных кристаллов (SCCL - Рисунок
\ref{chip1}) и одного кристалл интерфейса (SICL - Рисунок \ref{chip2} ).

\begin{figure}[htbp]
	\centering
	\includesvg[width = 180pt, inkscapelatex=false ]{SVG/wikichip1.drawio.svg}
	\caption{Схема целевого чипа.}
	\label{chip1}
\end{figure}
\begin{figure}[htbp]
	\centering
	\includesvg[width = 180pt, inkscapelatex=false ]{SVG/SICL.drawio.svg}
	\caption{SICL модуль.}
	\label{chip2}
\end{figure}



Кристалл
интерфейса, соединенный через общую шину, содержит модуль ускорителя
криптографии, интерфейсы ввода/вывода, PCIE и т.п. Каждый вычислительный
кристалл содержит 8 кластеров центрального процессора (CCL). В свою
очередь, кластер центрального процессора состоит из 4х вычислительных ядер,
4х блоков кэширования первого уровня (64К для данных и 64К для инструкций),
4х блоков кэшировния второго уровня и блока тэгов для кэша третьего
уровня. Кэш третьего уровня располагается отдельно внутри вычислительного
кристалла, присоединенный к общей шине, в нем также могут храниться данные
из других вычислительных кристаллов. Каждое ядро представляет собой
4-х канальный суперскалярный модуль с возможностью нарушения порядка
исполнения (superscalar, out-of-order).



\underline{\textbf{В разделе 2.2}} оописаны два основных пакета приложений, на которых демонстрировались результаты разработанных методов : SpecCPU и CPUBench. "SpecCPU 2017"\phantom{} - набор тестов для оценки производительности вычислительных
систем. Большая часть текущего исследования сосредоточена
на улучшение производительности тестов с целочисленной арифметикой,
однако некоторые общие подходы также применимы и к программам, использующим
вычисления с плавающей точкой. Считается, что набор тестов
SpecCPU является представителем современного рынка вычислений, поэтому
многие компании при покупке вычислительных систем сравнивают производительность
с использованием именно этого набора тестов. 

В 2023 году Китайский институт электроники и стандартизации выпустил
новый набор тестов производительности для вычислительных систем.
В отличие от набора SpecCPU,  интерфейс CPUBench разработан на языке python, а сам пакет имеет в себе программы, написанные на языке java. Авторами утверждается, что данный набор
тестов является своеобразным расширением "SpecCPU 2017"\phantom{}, которое нацелено на
лучшее покрытие мирового рынка (в том числе китайского). Было продемонстрировано
на 14 различных платформах, что данный набор тестов сохраняет
корреляцию производительности, показываемую пакетом SpecCPU.

Можно заметить некоторую схожесть пакета "CPUBench int"\phantom{} с пакетом
"SpecCPU int"\phantom{}. Так, вместо интерпретатора языка perl представлен интерпретатор
более современного языка python, добавлен дополнительный алгоритм компрессии/
декомпрессии, парсинг XML документов заменен на парсер JSON файлов.
А вот алгоритмов искусственного интеллекта здесь не наблюдается, зато присутствуют
базы данных MySQL и криптографический инструмент openssl.
Что касается тестов с плавающей точкой, большинство представленных
программ в SpecCPU можно разделить на 2 категории: работа с графическими
объектами и научные вычисления, в то время как в пакете CPUBench из графических
приложений можно увидеть только алгоритм трассировки лучей. Однако
CPUBench содержит в себе библиотеку градиентного бустинга lightgbm, активно
применяющуюся в машинном обучении.



\underline{\textbf{В разделе 2.3}} излагается методология получения результирующих цифр,
основанная на многолетнем научном опыте.
Пусть $REF\_TIME_i$ - время исполнения теста, на некоторой референтной машине, пусть наш набор содержит $M$ тестов, каждый из которых мы запускаем $N$ раз, то итоговое значение производительности оценивается по следующей формуле.

$$RATE =\left(\prod _{i=1}^{M}\dfrac{REF\_TIME_i}{MEDIAN(TIME_{i1}, TIME_{i2}, ... , TIME_{iN})}\right)^{\frac {1}{M}} $$

Также важной частью считается настройка окружающей системы, направленная
на уменьшение флуктуаций времени исполнения тестов и лучшей
утилизации тестовой системы.  Автор разбирает следующие проблемы, с которыми он столкнулся во время проведения замеров для алгоритмов, реализованных в
данной диссертации.
\begin{enumerate}
	\item Троттлинг.
	\item Неполная утилизация ресурсов системы. 
	\item Рандомизация размещения адресного пространства (ASLR).
	\item Частота обновления оперативной памяти.
	\item Занятость ресурсов внешними программами.
\end{enumerate}

\underline{\textbf{В разделе 2.4}} приводятся основные методы изучений целевых приложений
для последующей разработки компилятивных алгоритмов. Рассмотрены методы различного типа профилирования: \textbf{gprof}, \textbf{perf}, \textbf{callgrind}, симуляция целевой архитектуры на \textbf{GEM5} и обратная разработка с помощью \textbf{Radare2}.



\underline{\textbf{Третья глава}} посвящена описанию разработанных оптимизаций. Не все представленные
оптимизации были приняты сообществом openEulerGCC \footnote{https://gitee.com/src-openeuler/gcc/} по разным причинам.
Некоторые из описанных далее оптимизаций будут представлены сообществу
позднее, а некоторые, возможно, будут заменены другими подходами. Тем не
менее автор считает, что исследованные подходы также представляют научный
интерес.

\underline{\textbf{В разделе 3.1}} описаны улучшения существующих оптимизаций в компиляторе GCC. Изложение начинается с преобразования условных переходов (If-conversion), которое заменяет инструкцию перехода и зависящий
от него поток управления предикатным исполнением, соединяя тем самым две
различные ветки потока управления в одну для последующего совместного исполнения. Обычно эта оптимизация основана на представлении
SSA, однако в компиляторе GCC используется другой подход. На этом этапе
SSA-форма отсутствует, что может привести к невозможности проведения преобразования из-за одинаковых имен определений в базовых блоках.  Предлагаемое решение содержит принудительное переименование регистров. Регистры коллизий определяются как:
$$rename\_candidates = DEFS_{left\_bb} \cap USES_{right\_bb} $$

Если $rename\_candidates[i]$ все еще жив в конце базового блока $BB$, то трансформация не может быть применена.

Подобная оптимизация имеет определенные ограничения: слишком агрессивное преобразование может привести к излишнему перекладыванию данных на стек в случае нехватки регистров или к замедлению производительности, связанному с ограниченной возможностью аппаратуры распаралеливать исполнение скалярного кода (Super Scalar).  Поэтому вводятся функции
стоимости для данной оптимизации: главным, однако далеко не единственным
критерием применения преобразования условных переходов является итоговый
размер базового блока. В разработанной модели этот параметр может задаваться
пользователем, однако на исследуемой машине эмпирически был выведен
ограничивающий размер результирующего базового блока, равный 48 инструкциям.


Другим примером, приводимым в данном разделе, является  векторизация циклов с небольшим числом итераций.  В ходе текущего исследования было обнаружено, что векторизация
генерирует "хвосты"\phantom{ }(т. е. векторизованный код для меньшего коэффициента
векторизации), но не использует их, когда фактическое количество итераций
равно коэффициенту векторизации "хвоста".  Чтобы это исправить, предлагается простое решение в виде добавление дополнительной проверки во время исполнения и , если итерационное пространство все еще может быть векторизовано, то такой цикл необходимо исполнить в "хвостовой"\phantom{ }части оригинальной векторизации.

 \underline{\textbf{В разделе 3.2}} посвящен шаблонным  оптимизациям. Первым примером является оптимизация двойного умножения - шаблонное преобразование
 компилятора, предназначенное для преобразования алгоритма 64-битного умножения
 в эффективные инструкции. Таким образом, программа может лучше
 использовать возможности аппаратуры и повысить производительность всего
 приложения.
 
 Такие вычисления отыскиваются с использованием существующего механизма поиска шаблонов GCC и преобразуются в одиночные умножения более широких типов.
 
 
 Еще одним примером шаблонных оптимизация является шаблонное преобразование криптографических алгоритмов. Целевая машина имеет на плате расширение криптографии,
 которое включает специальные инструкции для crc32 и AES. Их можно использовать
 напрямую через встроенный язык ассемблера или встроенные функции
 компилятора. Добавлены оптимизационные проходы внутри компилятора, которые могут определять
 возможность использования инструкций в соответствии с семантикой
 кода.
 Оптимизация отыскивает весь алгоритм, включая предварительно
 рассчитанные таблицы, и статически проверяет, что все предварительно
 рассчитанные таблицы не изменяются во время выполнения.
 
 Следующие шаги описывают преобразование шаблона AES:
 \begin{enumerate}
 	\item \textbf{Сбор ссылок на таблицы AES}: Разработан оптимизационный проход внутри компилятора GCC для поиска ссылки на соответствующие таблицы шифрования/дешифрования AES. Такие инструкции являются отправной точкой для дальнейшего анализа.
 	\item \textbf{Формирование раундов AES}: Анализируются ссылки на таблицы и собираются инструкции, выполняющие вычисления, относящиеся к AES. связывая их вместе в блоки и раунды.
 	\item \textbf{Проверка шаблона AES}: Анализируются раунды и связываются вместе.
 	\item \textbf{Генерация кода AES}: Генерируется код AES для всех найденных раундов.
 \end{enumerate}
 
 
 
 Последним примером шаблонных оптимизаций является шаблонная подстановка инструкций. Одной из основных задач компилятора является выбор наиболее
 подходящих инструкций, которыми можно будет лаконично
 и в то же время оптимально с точки зрения производительности выразить
 внутреннее представление программы.
 
 Так, арифметическое выражение вида  
 \begin{flalign*}  \label{eq10}
 	B = (((A &>> 15) \& 0x00010001) << 16) -\\
 	((A &>> 15) \& 0x00010001)
 \end{flalign*}
 
  может быть транслировано в (Листинг  \ref{optimal1})
 
 \begin{ListingEnv}[!h]
 	\captiondelim{ } % разделитель идентификатора с номером от наименования
 	\caption{Оптимальный выбор инструкций.}\label{optimal1}
 	\begin{Verb}
 		uzp1 v17.8h, v18.8h, v17.8h
 	\end{Verb}
 \end{ListingEnv} 
 
 \underline{\textbf{В разделе 3.3}} описывается два метода оптимизации косвенных переходов: статический и динамический.
 
 Статический подход основан на анализе сигнатур функций. Предлагается анализировать
 сигнатуры функций для определений и вызовов. Если сигнатура вызываемой
 функции совпадает с сигнатурой определения то функция
 определения считается кандидатом.  В случае
 единственного кандидата, косвенный вызов функции заменяется
 вызовом найденной процедуры. Если же кандидатов несколько, то приходится
 выстраивать цепочку сравнений адресов переходов. что не
 всегда является оптимальным
 
 
 Динамический метод наследует идею JIT-компиляции (Just-in-Time
 compilation), однако здесь предлагается
 добавить буферный участок кода, который будет модифицироваться во время исполнения приложения.
 Статический компилятор (GCC)  оборачивает косвенный вызов функции в специальное библиотечное макро-определение  "DDL\_GOTO"\  или "DDL\_CALL". Внутри определения вместо каждой инструкции
 перехода генерируется "окно"\phantom{} в виде заранее определенного
 количества NOP инструкций и вызовов библиотечных функций сбора
 статистики и замены инструкций NOP условными переходами при
 превышении счетчиков. Оригинальный косвенный переход
 сохраняется в самом конце. Во время исполнения пользовательской  программы отдельные ее участки начинают работать, как JIT-компиляторы: собирать статистику и принимать решение о ретрансляции участка. Однако накладывается ограничение в виде конечного пространства в памяти для трансформации, которое было заложено статическим компилятором. Такой подход позволяет динамически ранжировать таблицу переходов во время исполнения.
 
 Статический подход способствовал улучшению тестов tpcc и tpch. Динамический подход не показал эффективности на всем тестовом пакете, однако на небольших мотивационных тестах  наблюдается улучшение производительности до 200 \%, когда количество адресов перехода
 находится в диапазоне от 4 до 8, в иных случаях может наблюдаться деградация.
 Деградация в 10 \% также наблюдалась на отдельных тестах пакета
 "SpecCPU 2017"\phantom{}.
 
\underline{\textbf{Раздел 3.4}} посвящен разбиению широких инструкций доступа в память. В процессе исследования было обнаружено, что в двух случаях использование широкого доступа к памяти может
возникнуть потеря производительности. 
\begin{figure}[htbp]
	\centering
	\includesvg[width = 250pt, inkscapelatex=false ]{SVG/split_ldr.drawio.svg}
	\caption{Два случая, когда использование широкого доступа в память приводит к замедлению.}
	\label{splitsvg1}
\end{figure}


Один из них (см. рисунок \ref{splitsvg1}) - это хорошо известный "невыровненный доступ". Было выявлено, что широкий доступ к памяти должен быть кратен его формату, в противном случае производительность снижается (даже когда речь идет о загрузке 2х независимых регистров). С другой стороны, было показано, что Kunpeng 920 не может быстро обрабатывать зависимости чтения после загрузки в память, если они имеют разные размеры. Аппаратная оптимизация пересылки сохраняемого значения (store-to-load forwarding) не может быть выполнена в таком случае.

Для решения этой проблемы был разработан алгоритм,
который находит инструкцию определения для базового регистра адреса широкой
загрузки. Затем алгоритм ищет все использования этого определения,
кроме оригинального. Если алгоритм находит сохранение в память с той же
базой, то проверяется целесообразность разделения исходного широкого доступа
к памяти. Было выявлено, что такой подход разумен, если расстояние
между загрузкой и сохранением составляет менее 16 инструкций.
 
 
 
 \underline{\textbf{В разделе 3.5}} описывается использование информация из анализа диапазона значений в компиляторе для уменьшения размеров типов переменных, что можэет благоприятно сказаться на последующей векторизации. 
 
  \underline{\textbf{Раздел 3.6}} описывает проблему семантики "ленивых"\phantom{ }вычислений с точки зрения производительности конечного кода. Дело в том, что такая удобная с точки зрения программирования семантическая конструкция препятствуем стандартным алгоритмам  преобразования условных переходов и векторизации. Так, код из листинга \ref{lcv1} не может быть векторизован базовым алгоритмом из-за возможности выхода за границу массива и последующей ошибки сегментации.
  
   \begin{ListingEnv}[!h]
  	\captiondelim{ } % разделитель идентификатора с номером от наименования
  	\caption{Кандидат для векторизации "ленивых"\phantom{ } вычислений.}\label{lcv1}
  	
  	\begin{Verb}
	... code ...
	if (arr[len] != const1 || arr[len +1] != const2 
		|| arr[len+2] != const3  || arr[len+3] != const4) {
		/* some code */
	}
	... code ...
  	\end{Verb}
  \end{ListingEnv}
 
Решением данной проблемы стало версионирование кода на векторизованный участок и скалярный.  Передача управления на векторизованный участок происходит  только в случае, если динамическая проверка подтверждает, что все доступы в векторизованном коде будут находится в одной странице памяти.
 
 Данный подход вставляет в код одну дополнительную проверку, следовательно,
 в некоторых случаях время исполнения программы может увеличиться,
 однако на целевых тестах такого не наблюдалось, наоборот, наблюдалось ускорение
 теста gzip.
 
  \underline{\textbf{В разделе 3.7}} описывается алгоритм слияния "хвостов"\phantom{ } базовых блоков.  Было продемонстрировано, что самая  современная версия компилятора (GCC 14.2) генерирует в определенных ситуациях множество копий одного и того же кода. Объединение таких кусков может помочь оптимизации преобразования косвенных переходов, а также уменьшить размер исполняемого файла.  Алгоритм состоит в поиске частичных общих участков и объединении их  в единый базовый блок-наследник.  Оптимизация  не показала существенного улучшения производительности целевых приложений, однако деградации также не было обнаружено.
 
 \underline{\textbf{Раздел 3.8}} кратко описывает оптимизацию предзагрузки косвенных доступов в память. Алгоритм пытается распознать циклы на межпроцедурном уровне, найти индуктивные переменные, а затем вставить предзагрузку данных на случай следующего вызова функции для косвенной адресации. Здесь возникает та же проблема, что и для векторизации "ленивых"\phantom{ } вычислений, поэтому приходится вставлять схожую динамическую проверку на то, что все загрузки из памяти, которые необходимо сделать для вычисления следующего адреса доступа, находятся в уже доступных страницах. Также использует информация, если она доступна, о размере массивов, чтобы минимизировать накладные расходы динамической проверки.
 
  \underline{\textbf{раздел 3.9}} посвящен новой методологии подбора вероятностей условных переходов. Идея заключается в попытке повторить производительность, полученную с помощью технологии PGO без использования реального профиля. Для решения этой проблемы предлагается воспользоваться моделью машинного обучения, которая в качестве признаков будет принимать информацию об условном переходе и о структуре кода вокруг него. Тренировочный набор данных был создан с использованием набора программ из пакета
  ExeBecnh. Пакет содержит сотни маленьких приложений, которые
  можно быстро перетранслировать при необходимости. 
  
  На рисунке \ref{op:mlpgo1} изображен процесс сбора тренировочного набора данных.
  \begin{figure}[htbp]
  	\centering
  	\includesvg[width = 250pt, inkscapelatex=false ]{SVG/FlowMLPGO1.drawio.svg}
  	\caption{Сбор данных для тренировки.}
  	\label{op:mlpgo1}
  \end{figure}
  
  Для обучения используется библиотека \textbf{XGBoost}, которая строит решающие деревья над собранным набором данных, модель сохраняется в бинарном формате, для последующего использования в компиляторе (рисунок \ref{op:mlpgo2}).
  
  \begin{figure}[htbp]
  	\centering
  	\includesvg[width = 250pt, inkscapelatex=false ]{SVG/FlowMLPGO2.drawio.svg}
  	\caption{Тренировка модели.}
  	\label{op:mlpgo2}
  \end{figure}
  Наконец, обученная модель может прогнозировать вероятности  переходов  без использования каких-либо данных профиля, а новый проход в компиляторе GCC включает оптимизации с профилем. Библиотека \textbf{XGBoost} имеет API на языке C, который позволяет интегрировать этап прогнозирования в проход без использования \textbf{Python}. Достаточно обучить модель один раз, чтобы потом использовать ее постоянно. Во время процесса компиляции  анализ собирает информацию об условных переходах  внутри программы в векторе признаков и передает ее функции \textbf{XGBoost} для прогнозирования. Результатом стало улучшение производительности тестов gromacs и openfoam на 10 \% и 5 \%  соответственно, однако присутствовала деградация в 5 \% на тесте phyml. Такой результат показывает целесообразность дальнейших исследований в этой области.
  \begin{figure}[htbp]
  	\centering
  	\includesvg[width = 250pt, inkscapelatex=false ]{SVG/FlowMLPGO3.drawio.svg}
  	\caption{Запуск модели во время компиляции целевого приложения.}
  	\label{op:mlpgo3}
  \end{figure}
 	
  \underline{\textbf{В разделе 3.10}}
  
  Ранее упоминались существенные преимущества преобразования условных переходов. Однако \underline{\textbf{в разделе 3.10}} продемонстрирована в некотором смысле обратная оптимизация. Рассмотрим немного упрощенный пример из теста phyml на листинге \ref{opt:ifsplit1}.
  \begin{ListingEnv}[!h]
  	\captiondelim{ } % разделитель идентификатора с номером от наименования
  	\caption{Пример кандидата для оптимизации разбиения условных выражений из теста phyml.}\label{opt:ifsplit1}
  	\begin{Verb}
  		if(tree->mod->ns == 4 || tree->mod->ns == 20) {	
  			foo(tree);
  		}
  	\end{Verb}
  \end{ListingEnv}
  
   Такое выражение накладывает на переменную $ns$ ограничение ($ns==4$ или $ns==20$). К сожалению работа с такого рода решеткой очень затруднительна для оптимизации распространения констант. Поэтому предлагается облегчить работу таким проходам (локальному и глобальному  распространению константных выражений) трансформировав такой в листинг \ref{opt:ifsplit2}.
  \begin{ListingEnv}[!h]
  	\captiondelim{ } % разделитель идентификатора с номером от наименования
  	\caption{Преобразованный листинг \ref{opt:ifsplit1}.}\label{opt:ifsplit2}
  	\begin{Verb}
  		if(tree->mod->ns == 4) {	
  			foo(tree);
  		} else if (tree->mod->ns == 20) {
  			foo(tree);
  		}
  	\end{Verb}
  \end{ListingEnv}
  
  Такой подход может приводить к существенному увеличению размера целевого кода, поэтому оптимизация накладывает ограничения на количество инструкций внутри функции(й).
  
  \underline{\textbf{В разделе 3.11}} приводятся результаты замеров производительности на тестах пакета SpecCPU (Рисунки \ref{fig:spec_int_speedup} и \ref{fig:spec_fp_speedup}) и CPUBench (Рисунки \ref{fig:spubench_int_speedup} и \ref{fig:spubench_fp_speedup} ).
  
  \begin{figure}[ht]
  	\centerfloat{
  		\includegraphics[scale=0.25]{PNG/speedup_combined3.png}
  	}
  	\caption{Результаты замеров производительности на тестах  пакета "CPUBench int"\phantom{}.}\label{fig:spubench_int_speedup}
  \end{figure}
    \begin{figure}[ht]
  	\centerfloat{
  		\includegraphics[scale=0.25]{PNG/speedup_combined3_fp.png}
  	}
  	\caption{Результаты замеров производительности на тестах  пакета "CPUBench fp"\phantom{}.}\label{fig:spubench_fp_speedup}
  \end{figure}
  
  \begin{figure}[ht]
  	\centerfloat{
  		\includegraphics[scale=0.15]{PNG/spec_speedup.png}
  	}
  	\caption{Результаты замеров производительности на тестах  пакета "SpecCPU int"\phantom{}.}\label{fig:spec_int_speedup}
  \end{figure}
    \begin{figure}[ht]
  	\centerfloat{
  		\includegraphics[scale=0.25]{PNG/spec_speedup_fp.png}
  	}
  	\caption{Результаты замеров производительности на тестах  пакета "SpecCPU fp"\phantom{}.}\label{fig:spec_fp_speedup}
  \end{figure}
  
%Можно сослаться на свои работы в автореферате. Для этого в файле
%\verb!Synopsis/setup.tex! необходимо присвоить положительное значение
%счётчику \verb!\setcounter{usefootcite}{1}!. В таком случае ссылки на
%работы других авторов будут подстрочными.
%Изложенные в третьей главе результаты опубликованы в~\cite{vakbib1, vakbib2}.
%Использование подстрочных ссылок внутри таблиц может вызывать проблемы.%

\FloatBarrier
\pdfbookmark{Заключение}{conclusion}                                  % Закладка pdf
В \underline{\textbf{заключении}} приведены основные результаты работы, которые заключаются в следующем:

\begin{enumerate}
	\item На основе анализа современных технологий оптимизации приложений были выдвинуты гипотезы и направления исследования для последующей их оптимизации с учетом недостатков целевой архитектуры.
	\item Предварительный анализ производительности с помощью таких приложений как \textbf{perf, radare2, GEM5} позволил доказать наличие возможности  для оптимизаций целевых приложений на исследуемой микроархитектуре. 
	\item Для выполнения поставленных задач было создано семь дополнительных проходов в компиляторе GCC, а также предложено 5 улучшений существующих оптимизаций.
	\item Разработанное решение позволило продемонстрировать улучшение производительности в ~11 \% на целевых тестах пакета "CPUBench int"\phantom{}  с улучшением до 74 \% на отдельных приложениях. 
	\item Разработанное решение позволило продемонстрировать улучшение производительности в ~6 \% на целевых тестах пакета "CPUBench fp"\phantom{}  с улучшением до 40 \% на отдельных приложениях. Для тестов пакета "CPUBench fp"\phantom{} улучшение производительности на  одном ядре существенно отличается и составляет ~12 \% на целевых тестах.
\end{enumerate}

В заключение хочется выразить благодарность всем коллегам и студентам, без которых данная работа не была бы возможной. Отдельная благодарность и большая признательность выражается научном руководителю Доброву А.Д за поддержку и помощь на всем научном пути автора.
\pdfbookmark{Литература}{bibliography}                                % Закладка pdf
%При использовании пакета \verb!biblatex! список публикаций автора по теме
%диссертации формируется в разделе <<\publications>>\ файла
%\verb!common/characteristic.tex!  при помощи команды \verb!\nocite!

\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=false}}{} % не рекомендуется применять пакет микротипографики к автоматически генерируемому списку литературы
\urlstyle{rm}                               % ссылки URL обычным шрифтом
\ifnumequal{\value{bibliosel}}{0}{% Встроенная реализация с загрузкой файла через движок bibtex8
    \renewcommand{\bibname}{\large \bibtitleauthor}
    \nocite{*}
    \insertbiblioauthor           % Подключаем Bib-базы
    %\insertbiblioexternal   % !!! bibtex не умеет работать с несколькими библиографиями !!!
}{% Реализация пакетом biblatex через движок biber
    % Цитирования.
    %  * Порядок перечисления определяет порядок в библиографии (только внутри подраздела, если `\insertbiblioauthorgrouped`).
    %  * Если не соблюдать порядок "как для \printbibliography", нумерация в `\insertbiblioauthor` будет кривой.
    %  * Если цитировать каждый источник отдельной командой --- найти некоторые ошибки будет проще.
    %
    %% authorvak
    \nocite{vakbib1}%
    \nocite{vakbib2}%
    %
    %% authorwos
    \nocite{wosbib1}%
    \nocite{E240105}%
    \nocite{chernonog2023статический}%
    \nocite{chernonog2024widemem}%
    \nocite{confmiptlazy}%
    \nocite{confmiptml1}%
       
    %
    %% authorscopus
    \nocite{scbib1}%
    %
    %% authorpathent
    %\nocite{patbib1}%
    %
    %% authorprogram
    \nocite{progbib1}%
    %
    %% authorconf
    \nocite{confbib1}%
    \nocite{confbib2}%
    %
    %% authorother
    \nocite{bib1}%
    \nocite{bib2}%

    \ifnumgreater{\value{usefootcite}}{0}{
        \begin{refcontext}[labelprefix={}]
            \ifnum \value{bibgrouped}>0
                \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
            \else
                \insertbiblioauthor      % Вывод всех работ автора
            \fi
        \end{refcontext}
    }{
        \ifnum \totvalue{citeexternal}>0
            \begin{refcontext}[labelprefix=A]
                \ifnum \value{bibgrouped}>0
                    \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
                \else
                    \insertbiblioauthor      % Вывод всех работ автора
                \fi
            \end{refcontext}
        \else
            \ifnum \value{bibgrouped}>0
                \insertbiblioauthorgrouped    % Вывод всех работ автора, сгруппированных по источникам
            \else
                \insertbiblioauthor      % Вывод всех работ автора
            \fi
        \fi
        %  \insertbiblioauthorimportant  % Вывод наиболее значимых работ автора (определяется в файле characteristic во второй section)
        \begin{refcontext}[labelprefix={}]
            \insertbiblioexternal            % Вывод списка литературы, на которую ссылались в тексте автореферата
        \end{refcontext}
        % Невидимый библиографический список для подсчёта количества внешних публикаций
        % Используется, чтобы убрать приставку "А" у работ автора, если в автореферате нет
        % цитирований внешних источников.
        \printbibliography[heading=nobibheading, section=0, env=countexternal, keyword=biblioexternal, resetnumbers=true]%
    }
}
\ifdefmacro{\microtypesetup}{\microtypesetup{protrusion=true}}{}
\urlstyle{tt}                               % возвращаем установки шрифта ссылок URL
